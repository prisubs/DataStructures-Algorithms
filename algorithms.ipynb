{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Algorithm    | Purpose                                                                                                                                                                                                                                                                                                                                                                                                                  | Steps                                                                                                                                                                                                                                                                                                                                                                                                            | Runtime                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
    "| ------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| Djikstra     | - Given a tree with $V$ vertices and $E$ edges<br>- Find the shortest paths tree from some node to every single other node in the graph                                                                                                                                                                                                                                                                              | - Start with a `PriorityQueue` of vertices ordered by distance from a node to the source node<br>- Add all items, keep track of their `distanceToSource` (starts out at $\\infty$) and their `sourceVertex` for convenience<br>- Visit items in order of their `distanceToSource`, smallest distances are visited first<br>- Keep visiting nodes until the `PriorityQueue` is empty                             | Full runtime is $O(V* log V + V * log V + E* log V)$, but since for a graph where Dijkstra’s would be useful, $E > V$, we can simplify the runtime to $O(ElogV)$.<br><br>This runtime is due to all of the `PriorityQueue` operations we have to do, because every edge has to be added, removed, sometimes `changePriority`, and those all have logarithmic contributions to the overall runtime. |\n",
    "| Heuristic A* | - Dijkstra’s for a single path between nodes $A$ and $B$ is inefficient, we need to make a guess in the right direction for it to be correct<br>- This ‘guess’ in `A*` is called a heuristic function. <br>- The choice of heuristic matters, because if it is admissible and consistent, then it will give the right answer all the time.<br>- This is algorithmically pretty much the same as Dijkstra’s algorithm | - Start with a `PriorityQueue` ordered by distance from a node to the source node<br>- Add all items, keep track of their `distanceToSource` added to their individual heuristic value `h(v)` (starts out at $\\infty$) and their `sourceVertex` for convenience<br>- Visit items in order of their `distanceToSource`<br>- Keep visiting nodes until the `PriorityQueue` is empty                              | The exact runtime depends on the quality of the heuristic. <br><br>- Heuristics need to be two things.<br>- Admissible, or never overestimates the real cost of reaching the goal vertex<br>- Consistent, or estimate is always <= to the estimated distance from any neighboring vertex to the goal, plus the cost of reaching that neighbor                                                            |\n",
    "| Prim         | - Finding the Minimum Spanning Tree, which is a subgraph of G, where T is connected, acyclic, includes all vertices with the smallest possible sum.<br>- MST encompasses all vertices, but not all edges.                                                                                                                                                                                                                | - Dijkstra’s algorithm, but where we consider vertices in order of the distance from the current `MST` we have constructed, rather than from source where we started.<br>- Starting from any arbitrary source, repeatedly add the shortest edge that connects some vertex in the tree to some vertex outside the tree. <br>- What source we pick doesn’t matter.<br>- Adds the lightest, acyclic, connected edge | - Like Dijkstra’s, the runtime is $O(ElogV)$<br>- Operations<br>    - Initializing a data structure to hold current progress<br>    - Changing that structure to reflect edges we have added to the MST                                                                                                                                                                                                |\n",
    "| Kruskal      | - Same as Prim’s, just a different way to solve the same problem.                                                                                                                                                                                                                                                                                                                                                        | - Initialize the MST to be empty<br>- Consider every single edge $E$ in order of edge weight<br>- If adding $E$ to the MST does not result in a cycle, add it to the considered edge<br>- Adds the lightest, acyclic edge. Doesn’t matter if it’s connected to the current `MST` or not.                                                                                                                     | - $O(ElogE)$<br>- Operations<br>    - All edges + weights have to be added to original data structure<br>    - Keep performing `removeMin` operations until no more light, acyclic edges remain in structure                                                                                                                                                                                           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Algorithm              | Purpose                                                                                                                                                                                                                                                                                                                                                                                                                | Procedure                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | Runtime                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
    "| ---------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| Selection Sort         | - Sorting an array in place<br>- Naively very slow, we can use better things                                                                                                                                                                                                                                                                                                                                           | - In place, split the array into sorted and unsorted “sections” without actually creating anything new<br>- Successively identify the most extreme element and insert it into the sorted section<br>- Repeat until no more unsorted elements are left                                                                                                                                                                                                                                                                                                                                                                  | - For each element, we have to perform an average of $n/2$ comparisons.<br>- Runtime overall is $O(N^{2})$<br>    - Best case is for a sorted array, and we would only need to look through each element without moving it<br>    - Worst case is an array in opposite order, because not only do we have to look through everything, we also have to move everything the most possible number of spaces                                                                 |\n",
    "| Heap Sort              | - Naively, using a heap based `PriorityQueue` to sort the items since that will do the organizing <br>- Cleverly, treating the unsorted array as a heap and successively adjusting it into sorting                                                                                                                                                                                                                     | - `NaiveHeapSort` <br>    - Insert all items into a `MaxPQ` and remove them one by one. <br>    - Put them into a result sorted array<br>- `SmartHeapSort`<br>    - Heapify the array using bottom-up construction, swapping elements as needed<br>    - Heapifying is sinking items in reverse-level order to their appropriate place in the final heap<br>    - Repeatedly `deleteMax` and move that item to the end, re-heapifying along the way to maintain validity                                                                                                                                               | - `NaiveHeapSort` <br>    - Heap construction takes $N$$log(N)$<br>    - Heap iteration takes $N$ time <br>    - Overall $\\theta(NlogN)$ runtime.<br>- `SmartHeapSort` <br>    - Runs in the same speed<br>    - Less memory usage since we don’t construct two data structures.                                                                                                                                                                                     |\n",
    "| Merge Sort             | - Recursive algorithm<br>- Uses the “divide and conquer” method to keep recursively sorting itself<br>- In-place sort, no additional structures needed                                                                                                                                                                                                                                                                 | - Divide input array into two halves<br>- Call self on each half created<br>- Merge the two sorted resulting halves that result as a consequence of the recursive calls before self<br>- Base case is when the split array is a single element                                                                                                                                                                                                                                                                                                                                                                         | - Runs in $\\theta(NlogN)$ <br>    - $log(N)$ levels of recursive tree<br>    - Subproblem is halving in size on each iteration of the algorithm<br>    - Work at each level sums up to N<br>- This bound doesn’t change dramatically with different inputs.                                                                                                                                                                                                              |\n",
    "| Insertion Sort         | - Uses the principle of inversions to sort<br>- An inversion is a set of elements in an array that are out of order. <br>    - For example, a completely sorted array will have no inversions<br>    - The array `[1, 2, 5, 4, 7, 6]` has two inversions, since two pairs of elements need to be swapped for the array to be in order<br>- Good for small $N$ where the data is mostly sorted to some degree already | - `NaiveInsertionSort` <br>    - Creation of a separate data structure to hold sorted result. <br>    - Algorithm same as below<br><br><br>- `SmartInsertionSort`<br>    - Begin at the rightmost element<br>    - Swaps items one-by-one towards the left until correct position<br>    - Requires that every item to the left of position i is in sorted order, and everything to the right has not yet been examined. <br>    - Every swap fixes exactly one inversion.                                                                                                                                             | - Best Case<br>    -  $\\theta(N)$ time. <br>    - This is for a sorted array<br>    - You have to make no swaps.<br>- Worst case<br>    -  $\\theta(N^{2})$ time<br>    - This occurs when the list is in the opposite order of what you want<br>    - Maximum number of inversions implies maximum possible upper bound on runtime<br>- More generally, runtime is no worse than the number of inversions.                                                               |\n",
    "| Quick Sort             | - Fastest for arrays that are quite randomized<br>- Many partitioning strategies/implementations<br>- However, choice of strategies for partitioning and pivots are important, they affect the runtime.<br>- For most real world situations, quicksort is the fastest sort.<br>- Works especially well for integers, or other primitives where stability is irrelevant to us.                                          | - Partitioning Principle<br>    -  All items to the left of the pivot are $\\leq$ and all items to the right are $\\geq$. <br>- `QuickSort`<br>    - Partition array around some pivot, usually leftmost element<br>    - `quickSort(left)` and `quickSort(right)` <br>    - Repeat process until sorted<br>- Hoare Partitioning<br>    - In place strategy for partitioning<br>    - Two pointers, one at left (small-loving), one at right (large-loving) which swap, walking inwards<br>    - Swap occurs when both pointers land on a hated item<br>    - When pointers cross, swap pivot with the right pointer | - Average $\\theta(NlogN)$<br>- Other Cases<br>    - With a bad pivot or bad array case, we can also end up with a worst case $O(N^{2})$<br>    - The best case is when the pivot ends up around the middle of the list every single time<br>- Avoiding Worst Case<br>    - Picking a random pivot <br>    - Shuffling an array before sorting <br>    - Pivoting on the median<br>    - Watching recursion depth                                                         |\n",
    "| Topological Sort       | - Graph needs to be acyclic, directed, running a `DFS` process but with a sequential flow<br>- Linear ordering of vertices so that everything is visited in a particular order<br>- Useful for things like workflows where steps have to be sequential<br>- Not unique, multiple potential orders                                                                                                                      | - Start the search at `inDegree` 0, or a vertex without anything going into it<br>- Perform a `DFS` traversal from each node that has no `inDegree`, but don’t clear markings in between<br>- `TopologicalValue` is given by the reversed DFS postorder list                                                                                                                                                                                                                                                                                                                                                           | - Note: `SPT` on a `DAG` can be run by relaxing edges in topological sorting order<br>- Topological sort runs in $O(V+E)$, which is simply `DFS` with an extra computational stack.                                                                                                                                                                                                                                                                                        |\n",
    "| Counting Sort          | - Stable algorithm<br>- Best where keys are small integers<br>- Only works well for keys in a particular alphabet, such as english single characters or numbers < 10                                                                                                                                                                                                                                                   | - This is a non-comparative sort<br>- Determine the staring position in a sorted array of each type<br>- Go through each element in the unsorted array, and determine its position in the sorted array, inserting it accordingly as you go                                                                                                                                                                                                                                                                                                                                                                             | - $\\theta(N+R)$ where $R$ is the alphabet size<br>- Best case is where $R << N$, if we get the other way around, bound approaches quadratic (bad) performance                                                                                                                                                                                                                                                                                                          |\n",
    "| Radix Sort             | - Counting sort applied to each part of a longer, alphabetized key<br>- Keys useful for radix sort include long integers, alphanumeric strings, and english words<br>- These are good because while the whole key does not come from an “alphabet”, each digit of the key does, so we can perform a repeated counting sort                                                                                             | - `LSD` [least significant digit]<br>    - Counting sort that considers digits in order of least to most significant<br>    - W/ unequal key lengths, pad keys with some uniformity value to make them all the same length<br>- `MSD` [most significant digit]<br>    - Counting sort that considers digits in order of most to least significant<br>    - To be accurate, must recursively sort each level to preserve order that resulted from the first source<br>    - To do this, we have to successively sort subarrays each time.                                                                               | - `LSD`<br>    - Multiple counting sorts<br>    - $\\theta(W(N+R))$ where $W$ is the width of each item we are sorting on<br>    - We are performing $W$ counting sorts<br>- `MSD`<br>    - Best case when all the first keys are different, runs in $\\theta(N+R)$ which is the same as a single pass of counting sort<br>    - Worst case is when all keys are the same, $\\theta(WN + WR)$ because we have to do a counting sort for every single digit of the key |\n",
    "| Quick Select           | - Finding the median <br>- For use as a partition in `QuickSort`                                                                                                                                                                                                                                                                                                                                                       | - Successively partition array, dividing it into multiple subproblems as we go<br>- We know median can never be to the left of the partition, so we only look at the right subproblem                                                                                                                                                                                                                                                                                                                                                                                                                                  | - Worst case $O(N^{2})$ actually occurs on a sorted array <br>- Average case is $\\theta(N)$ because we successively get $N, N/2 + N/2...$ items to work on                                                                                                                                                                                                                                                                                                             |\n",
    "| Compression Procedures | - Purpose is to find prefix free codes to compress bit sequences<br>- A prefix-free code is one where no codeword is a prefix of any other,  $\\therefore$ no ambiguity eliminates the need for “pauses” between bit sequences<br>- Goal is to calculate the best code for a certain text, build an efficient code structure                                                                                          | - `Shannon-Fano`<br>    - Split a tree into halves of roughly equal frequencies<br>    - Left half gets a leading one, right half gets a leading zero in its code<br>    - Technically suboptimal<br>- `Huffman`<br>    - Assign each symbol to a node corresponding to its frequency<br>    - Going from smallest nodes, successively merge nodes into “supernodes” until everything is part of a tree<br>    - Total weight of the tree sums to 1<br>    - Prefix 1 or 0 along the way<br>    - Implemented using `Trie`                                                                                             |                                                                                                                                                                     \n",
    "| \n",
    "| Floyd's Algorithm | Detects and finds a loop in a singly linked list | Create two pointers, one `fast` and one `slow`. `fast` moves by two nodes each iteration, and `slow` moves by only one. If these pointers ever meet at the same node, then there is a loop in the `SLL`. Otherwise, it contains no cycles. | Runs in $O(n)$ time due to having to essentially perform two traversals of the entire list, which are both contained in $N$. |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
